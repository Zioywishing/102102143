作业Github链接：https://github.com/Zioywishing/102102143

# 一、PSP表格

| 工作名称 | 预估耗时(分钟) | 实际耗时(分钟) |
|:--------| :--------- |:--------|
| 计划 | 3 | - |
| · 估计这个任务需要多少时间 | 3 | - |
| 开发 | 70 | 169 |
| · 需求分析(包括学习新技术) | 15 | 60(左右) |
| · 生成设计文档 | - | - |
| · 设计复审 | - | - |
| · 代码规范 | - | - |
| · 具体设计 | 10 | 2 |
| · 具体编码 | 15 | 27 |
| · 代码复审 | - | - |
| · 测试（自我测试，修改代码，提交修改） | 30 | 180(左右) |
| 报告 | 5 | 30 |
| · 测试报告 | - | - |
| · 事后总结, 并提出过程改进计划 | 5 | 30 |
| · 合计 | 78 | 199 |

注：未准确计时的环节通过结束时间减去开始时间得到耗时，以"(左右)"标注

# 二、任务要求的实现

- Q：**项目设计与技术栈**。从阅读完题目到完成作业，这一次的任务被你拆分成了几个环节？你分别通过什么渠道、使用什么方式方法完成了各个环节？列出你完成本次任务所使用的技术栈。
   
  A：1.我将这次任务分为寻找解决方案->写出伪代码->根据伪代码编码->对代码进行调试->为代码添加作业所需功能->对代码继续进行调试 这几个环节，其中所需要学习的内容全部通过网络搜索结果获取。2.本次任务主要用到了爬虫，python这样方面的技术栈。

- Q：**爬虫与数据处理**。说明业务逻辑，简述代码的设计过程（例如可介绍有几个类，几个函数，他们之间的关系），并对关键的函数或算法进行说明。

  A：这次任务我先通过bilibili的api爬取默认排序下的视频bv号至少300条，再通过api获取前300个bv号对应的oid值，最后通过oid值获得对应视频的弹幕库。将弹幕库内所有弹幕合并为1个list，再对这个list进行其他处理以满足任务需求，共1个类，其中包含16个函数。

- Q：**数据统计接口部分的性能改进**。记录在数据统计接口的性能上所花费的时间，描述你改进的思路，并展示一张性能分析图（例如可通过VS /JProfiler的性能分析工具自动生成），并展示你程序中消耗最大的函数。

  A：整个程序用时最长的部分为process_dms，共占用了45%的时间，而其中65%（总时间占比30%）的时间为wordcloud库中generate_from_frequencies生成词云所占用，而通过多线程爬取，其他部分的运行时间已经达到了完全可接受的程度。

- Q：**数据结论的可靠性**。介绍结论的内容，以及通过什么数据以及何种判断方式得出此结论。
  
  A：结论是bilibili用户的舆论倾向于去声援保护海洋，同时对日本排放污水的行为表示不满。

- Q：**数据可视化界面的展示**。在博客中介绍数据可视化界面的组件和设计的思路。
  
  A：我通过wordcloud，根据爬取下来的数据通过jieba分词以后排序前300的词生成词云图。选择wordcloud是因为它可以非常直观的反映当下的bilibili用户对于搜索关键词的反映。


# 三、心得体会

通过这次的作业，我深刻认识到我大学3年啥都没学，已经玉玉了。今后还有结队编程和组队编程的大作业，希望我能在速成那些编程工具以后及时完成作业，并为团队少拖一些后腿。